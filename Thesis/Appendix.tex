\appendix
\chapter{Numerical differentiation}\label{central_diff}
%\chapter*{Appendix}

The are a few ways to numerically approximate derivatives of functions and central differentiation is the most accurate one.

I want to estimate the slope of a curve $f$ at a certain point $t$ using $f(t)$ and the value of $f$ at a neighboring point $t + \Delta t$. As $\Delta t$ approaches zero, the slope approached the true derivative of $f$ at $t$:
\begin{equation}
    f'(t) = \lim_{\Delta t\to 0} \frac{f(t + dt) - f(t)}{\Delta t}.
\end{equation}
However, my goal is to estimate a derivative of a data set (discrete data points measured in time), hence above limit can be approximated as
\begin{equation}\label{eq:forward}
    f'(t) \approx \frac{f(t + dt) - f(t)}{\Delta t}.
\end{equation}
This is called a forward difference approximation to the derivative of $f$. Another approach would be to use the a neighboring point $t - \Delta t$ leading to a backward difference approximation to the derivative of $f$:
\begin{equation}\label{eq:backward}
    f'(t) \approx \frac{f(t) - f(t - dt)}{\Delta t}.
\end{equation}

In order to estimate the error of these approximations and consequently the error of the produced derivatives, I use a Taylor expansion of the $f(t + dt)$ term at the point $t$:
\begin{equation}\label{eq:forward_error}
    f(t + dt) = f(t) + \frac{df}{dt}(t) \Delta t + \frac{\Delta t^{2}}{2!} \frac{d^{2}f}{dt^{2}}(t) + \frac{\Delta t^{3}}{3!} \frac{d^{3}f}{dt^{3}}(t) + ... + O(\Delta t^{4}).
\end{equation}
Equivalently, I use a Taylor expansion of the $f(t - dt)$ term at the point $t$:
\begin{equation}\label{eq:backward_error}
    f(t - dt) = f(t) - \frac{df}{dt}(t) \Delta t + \frac{\Delta t^{2}}{2!} \frac{d^{2}f}{dt^{2}}(t) - \frac{\Delta t^{3}}{3!} \frac{d^{3}f}{dt^{3}}(t) + ... 
\end{equation}

By replacing \cref{eq:forward_error} to \cref{eq:forward}, I get:
\begin{equation}\label{eq:forward_approx}
    f'(t) = f'(t) + \frac{\Delta t}{2!} \frac{d^{2}f}{dt^{2}}(t) +...
\end{equation}
In \cref{eq:forward_approx}, the first term is the actual derivative, while the rest terms correspond to the error of the approximation. The same analysis is valid for the backward approximation, thus by replacing  \cref{eq:backward_error} to \cref{eq:backward}, I get:
\begin{equation}\label{eq:backward_approx}
    f'(t) = f'(t) - \frac{\Delta t}{2!} \frac{d^{2}f}{dt^{2}}(t) +...
\end{equation}

From \cref{eq:forward_approx} and \cref{eq:backward_approx} it is evident that the error of the aforementioned approximations in on the order of $\Delta t$. In principle, someone can make the error of these approximations smaller by making  $\Delta t$ smaller, but for a given data set $\Delta t$ is already defined. For example, the time step of a simulation defines the $\Delta t$ separating the data points of the data set.

A third approach to approximate the derivative of $f$ at $t$, is to use two neighboring points $t - \Delta t$ and $t + \Delta t$:
\begin{equation}\label{eq:central}
    f'(t) \approx \frac{f(t + dt) - f(t - dt)}{2\Delta t}.
\end{equation}
This is called a central difference approximation to the derivative of $f$. The advantage of central differentiation becomes clear by replacing \cref{eq:forward_error} and \cref{eq:backward_error} in \cref{eq:central}:
\begin{equation}\label{eq:central_approx}
    f'(t) = f'(t) + \frac{\Delta t^{2}}{3!} \frac{d^{3}f}{dt^{3}}(t) +...
\end{equation}
The leading error term in \cref{eq:central_approx} is now on the order of $\Delta t^{2}$. This is a really important upgrade. For example, if I want to reduce the error by a factor of 100, I need to reduce $\Delta t$ by a factor of 10. The importance of central differentiation becomes essential in calculations of accurate derivatives on data sets as with this scheme someone needs to collect 10 times less data points to have the same error as the previously mentioned schemes.






